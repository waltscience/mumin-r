---
title: A quick guide to using multi-model inference for model selecetion in R
output: rmarkdown::github_document
---
layout: post
image: /images/Electoral_Map_States.png
summary: Use computing power to choose the best fit model.
excerpt: Use computing power to choose the best fit model.
time: 3 minute read
title: A quick guide to using multi-model inference for model selecetion in R

<br>
**Use computing power to choose the best fit model.**

Model selection is a longstanding issue in statistical analysis. How should we choose the best model? Kenneth Burnham and David Anderson [argue we should be using insight from information theory to select models](https://www.springer.com/gp/book/9780387953649). Their approach is called Multi-Model Inference.

<br>
<br>

***

## How does multi-model inference work?

Very simply, multi-model inference works by testing all possible combinations of variables in a model and ranking them by their fit. Ranking is done using the [Aikaike Information Criterion (AIC)](https://en.wikipedia.org/wiki/Akaike_information_criterion). AIC is a measure of model fit, taking into account model simplicity. The aim of multi-model inference and AIC is to determine the best fit model using the fewest variables.

<br>
<br>

***

## Using multi-model inference in R

The package MuMIn has everything needed to perform multi-model inference. To test it out, we can use data from the University of Wisconsin County Health Project. This dataset contains health data from six states in the U.S.

<br>

```{r echo = TRUE, results = 'hide', message = FALSE, warning = FALSE}
packages <- c("readr", "MuMIn", "lme4")                 # packages you will need
lapply(packages, require, character.only = TRUE)        # install and / or load packages
dat <- as.data.frame(read_csv(url("https://raw.githubusercontent.com/waltscience/mumin-r/master/healthdata.csv")))
```

<br>

We will build models testing whether diabetes prevalence in counties in these states is related to the following factors:
 
 * Smoking
 * Food environment index
 * Physical inactivity
 * Access to exercise opportunities
 * Excessive drinking prevalence
 
We begin by building a model with these fixed effects and their two-way interactions, using county and state as random effects. We can think of this model as the "global" model.

<br>

```{r echo = TRUE, results = 'hide', message = FALSE, warning = FALSE}
mod <- lme(
          diabetesprevalence ~ 
            smoking +
            foodenvironment +
            physicalinactivity +
            accesstoexercise +
            excessivedrinking +
              smoking:foodenvironment +
              smoking:physicalinactivity +
              smoking:accesstoexercise +
              smoking:excessivedrinking +
              foodenvironment:physicalinactivity +
              foodenvironment:accesstoexercise +
              foodenvironment:excessivedrinking +
              physicalinactivity:accesstoexercise +
              physicalinactivity:excessivedrinking +
              accesstoexercise:excessivedrinking,
          random = ~ 1 | state/county, data = dat, method = "ML"
          )
```

<br>

From the global model, we will use the dredge function to test every model with all possible combinations of the fixed effects.

<br>

```{r echo = TRUE, results = 'hide', message = FALSE, warning = FALSE}
moddredge <- dredge(mod, extra = c("R^2", F = function(x)summary(x)$fstatistic[[1]]))



vrs <- data.frame("nam" = as.character("name"))
vrs$nam <- capture.output(cat(names(coefficients(av)[-1]), sep = " + "))
vrs$nam <- paste(vrs$nam, ", random = ~ 1 | state/county, data = dat, method='ML'", sep = "")
bestmod <- eval(parse(text = paste("lme(diabetesprevalence ~ ", vrs$nam, ")")))
summary(bestmod)
coef(summary(bestmod))
r.squaredGLMM(bestmod)
ptable <- cbind(coef(summary(bestmod)), Anova(bestmod, type = "III"), r.squaredGLMM(bestmod))
```

We can create a plot showing model variables vs. average model AIC to get a sense of what factors are important. Then create a model average from the models with the lowest AIC. Typically, models are not thought to be different if they are within three AIC, so the model.avg function creates an average model from models within that range. 


```{r}
plot(moddredge, labAsExpr = TRUE)
av <- model.avg(moddredge, subset = delta < 3)
```








